<pre>
Decision tree regression uses a decision tree (as a predictive model) to go from observations about an item to conclusions about the item's target value.

It is one of the predictive modelling approaches used in statistics, data mining and machine learning.
</pre>

<pre>
What is Decision Tree?

A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.
It is one way to display an algorithm.
</pre>
<pre>
Goal:

The goal is to create a model that predicts the value of a target variable based on several input variables.<br>
An example is shown in the diagram.

<img src = "../images/models/decisionTreeRegression.png">

Each interior node corresponds to one of the input variables; there are edges to children for each of the possible values of that input variable.
Each leaf represents a value of the target variable given the values of the input variables represented by the path from the root to the leaf.
</pre>
<pre>
What is this doing?

The decision trees is used to fit a sine curve with addition noisy observation.
As a result, it learns local linear regressions approximating the sine curve.
We can see that if the maximum depth of the tree (controlled by the max_depth parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.
</pre>